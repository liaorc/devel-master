const char *pgstrom_cuda_dynpara_code =
  "/*\n"
  " * cuda_dynpara.h\n"
  " *\n"
  " * Support routine for dynamic parallelism on CUDA devices.\n"
  " * Inclusion of this library makes cuda_program.c to link libcudadevrt.a.\n"
  " * --\n"
  " * Copyright 2011-2016 (C) KaiGai Kohei <kaigai@kaigai.gr.jp>\n"
  " * Copyright 2014-2016 (C) The PG-Strom Development Team\n"
  " *\n"
  " * This program is free software; you can redistribute it and/or modify\n"
  " * it under the terms of the GNU General Public License version 2 as\n"
  " * published by the Free Software Foundation.\n"
  " *\n"
  " * This program is distributed in the hope that it will be useful,\n"
  " * but WITHOUT ANY WARRANTY; without even the implied warranty of\n"
  " * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n"
  " * GNU General Public License for more details.\n"
  " */\n"
  "#ifndef CUDA_DYNPARA_H\n"
  "#define CUDA_DYNPARA_H\n"
  "\n"
  "#ifdef __CUDACC__\n"
  "#include <device_launch_parameters.h>\n"
  "/*\n"
  " * Macro to track timeval and increment usage.\n"
  " */\n"
  "#define TIMEVAL_RECORD(ktask,field,tv_start)\t\t\t\t\t\t\\\n"
  "\tdo {\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\\\n"
  "\t\t(ktask)->pfm.num_##field++;\t\t\t\t\t\t\t\t\t\\\n"
  "\t\t(ktask)->pfm.tv_##field +=\t\t\t\t\t\t\t\t\t\\\n"
  "\t\t\t((cl_float)(GlobalTimer() - (tv_start)) / 1000000.0);\t\\\n"
  "\t} while(0)\n"
  "\n"
  "/*\n"
  " * __occupancy_max_potential_block_size\n"
  " *\n"
  " * Equivalent logic with cudaOccupancyMaxPotentialBlockSize, but not supported\n"
  " * by the device runtime at CUDA 7.5, so we ported the same calculation logic\n"
  " * here.\n"
  " */\n"
  "STATIC_INLINE(cudaError_t)\n"
  "__occupancy_max_potential_block_size(cl_uint *p_minGridSize,\n"
  "\t\t\t\t\t\t\t\t\t cl_uint *p_maxBlockSize,\n"
  "\t\t\t\t\t\t\t\t\t const void *kernel_function,\n"
  "\t\t\t\t\t\t\t\t\t cl_uint dynamicShmemPerBlock,\n"
  "\t\t\t\t\t\t\t\t\t cl_uint dynamicShmemPerThread,\n"
  "\t\t\t\t\t\t\t\t\t size_t blockSizeLimit)\n"
  "{\n"
  "\tcudaError_t\t\tstatus;\n"
  "\n"
  "\t/* Device and function properties */\n"
  "\tstruct cudaFuncAttributes attr;\n"
  "\tint\t\t\t\tdevice;\n"
  "\n"
  "    /* Limits */\n"
  "\tint\t\t\t\tmaxThreadsPerMultiProcessor;\n"
  "\tint\t\t\t\twarpSize;\n"
  "\tint\t\t\t\tdevMaxThreadsPerBlock;\n"
  "\tint\t\t\t\tmultiProcessorCount;\n"
  "\tint\t\t\t\tfuncMaxThreadsPerBlock;\n"
  "\tint\t\t\t\toccupancyLimit;\n"
  "\n"
  "    /* Recorded maximum */\n"
  "    int\t\t\t\tmaxBlockSize = 0;\n"
  "    int\t\t\t\tnumBlocks    = 0;\n"
  "    int\t\t\t\tmaxOccupancy = 0;\n"
  "\n"
  "    /* Temporary */\n"
  "    int\t\t\t\tblockSizeToTryAligned;\n"
  "    int\t\t\t\tblockSizeToTry;\n"
  "    int\t\t\t\tblockSizeLimitAligned;\n"
  "    int\t\t\t\toccupancyInBlocks;\n"
  "    int\t\t\t\toccupancyInThreads;\n"
  "    int\t\t\t\tdynamicSMemSize;\n"
  "\n"
  "\t/* ------------------------------------------------\n"
  "\t *  Sanity checks\n"
  "\t * ------------------------------------------------ */\n"
  "\tif (!p_minGridSize || !p_maxBlockSize || !kernel_function)\n"
  "\t\treturn cudaErrorInvalidValue;\n"
  "\n"
  "\t/* ------------------------------------------------\n"
  "\t *  Obtain device and function properties\n"
  "\t * ------------------------------------------------ */\n"
  "\tstatus = cudaGetDevice(&device);\n"
  "\tif (status != cudaSuccess)\n"
  "\t\treturn status;\n"
  "\n"
  "\tstatus = cudaDeviceGetAttribute(&maxThreadsPerMultiProcessor,\n"
  "\t\t\t\t\t\t\t\t\tcudaDevAttrMaxThreadsPerMultiProcessor,\n"
  "\t\t\t\t\t\t\t\t\tdevice);\n"
  "    if (status != cudaSuccess)\n"
  "\t\treturn status;\n"
  "\n"
  "\tstatus = cudaDeviceGetAttribute(&warpSize,\n"
  "\t\t\t\t\t\t\t\t\tcudaDevAttrWarpSize,\n"
  "\t\t\t\t\t\t\t\t\tdevice);\n"
  "\tif (status != cudaSuccess)\n"
  "        return status;\n"
  "\n"
  "\tstatus = cudaDeviceGetAttribute(&devMaxThreadsPerBlock,\n"
  "\t\t\t\t\t\t\t\t\tcudaDevAttrMaxThreadsPerBlock,\n"
  "\t\t\t\t\t\t\t\t\tdevice);\n"
  "\tif (status != cudaSuccess)\n"
  "        return status;\n"
  "\n"
  "    status = cudaDeviceGetAttribute(&multiProcessorCount,\n"
  "\t\t\t\t\t\t\t\t\tcudaDevAttrMultiProcessorCount,\n"
  "\t\t\t\t\t\t\t\t\tdevice);\n"
  "    if (status != cudaSuccess)\n"
  "        return status;\n"
  "\n"
  "\tstatus = cudaFuncGetAttributes(&attr, kernel_function);\n"
  "\tif (status != cudaSuccess)\n"
  "\t\treturn status;\n"
  "\tfuncMaxThreadsPerBlock = attr.maxThreadsPerBlock;\n"
  "\n"
  "\t/* ------------------------------------------------\n"
  "\t *  Try each block size, and pick the block size with\n"
  "\t *  maximum occupancy\n"
  "\t * ------------------------------------------------ */\n"
  "\toccupancyLimit = maxThreadsPerMultiProcessor;\n"
  "\n"
  "\tif (blockSizeLimit == 0)\n"
  "\t\tblockSizeLimit = devMaxThreadsPerBlock;\n"
  "\n"
  "\tif (devMaxThreadsPerBlock < blockSizeLimit)\n"
  "\t\tblockSizeLimit = devMaxThreadsPerBlock;\n"
  "\n"
  "\tif (funcMaxThreadsPerBlock < blockSizeLimit)\n"
  "\t\tblockSizeLimit = funcMaxThreadsPerBlock;\n"
  "\n"
  "\tblockSizeLimitAligned =\n"
  "\t\t((blockSizeLimit + (warpSize - 1)) / warpSize) * warpSize;\n"
  "\n"
  "\tfor (blockSizeToTryAligned = blockSizeLimitAligned;\n"
  "\t\t blockSizeToTryAligned > 0;\n"
  "\t\t blockSizeToTryAligned -= warpSize)\n"
  "\t{\n"
  "\t\t/*\n"
  "\t\t * This is needed for the first iteration, because\n"
  "\t\t * blockSizeLimitAligned could be greater than blockSizeLimit\n"
  "\t\t */\n"
  "        if (blockSizeLimit < blockSizeToTryAligned)\n"
  "\t\t\tblockSizeToTry = blockSizeLimit;\n"
  "\t\telse\n"
  "            blockSizeToTry = blockSizeToTryAligned;\n"
  "\n"
  "\t\tdynamicSMemSize = (dynamicShmemPerBlock +\n"
  "\t\t\t\t\t\t   dynamicShmemPerThread * blockSizeToTry);\n"
  "\n"
  "        status = cudaOccupancyMaxActiveBlocksPerMultiprocessor(\n"
  "\t\t\t&occupancyInBlocks,\n"
  "\t\t\tkernel_function,\n"
  "\t\t\tblockSizeToTry,\n"
  "\t\t\tdynamicSMemSize);\n"
  "\t\tif (status != cudaSuccess)\n"
  "\t\t\treturn status;\n"
  "\n"
  "\t\toccupancyInThreads = blockSizeToTry * occupancyInBlocks;\n"
  "\n"
  "\t\tif (occupancyInThreads > maxOccupancy)\n"
  "\t\t{\n"
  "\t\t\tmaxBlockSize = blockSizeToTry;\n"
  "\t\t\tnumBlocks    = occupancyInBlocks;\n"
  "\t\t\tmaxOccupancy = occupancyInThreads;\n"
  "\t\t}\n"
  "\n"
  "\t\t/*\n"
  "\t\t * Early out if we have reached the maximum\n"
  "\t\t */\n"
  "\t\tif (occupancyLimit == maxOccupancy)\n"
  "\t\t\tbreak;\n"
  "\t}\n"
  "\n"
  "\t/* --------------------------------\n"
  "\t *  Return best available\n"
  "\t * -------------------------------- */\n"
  "\t*p_minGridSize  = numBlocks * multiProcessorCount;\n"
  "\t*p_maxBlockSize = maxBlockSize;\n"
  "\n"
  "\treturn status;\n"
  "}\n"
  "\n"
  "/*\n"
  " * optimal_workgroup_size - lead an optimal block_size from the standpoint\n"
  " * of performance.\n"
  " */\n"
  "STATIC_FUNCTION(cudaError_t)\n"
  "optimal_workgroup_size(dim3 *p_grid_sz,\n"
  "\t\t\t\t\t   dim3 *p_block_sz,\n"
  "\t\t\t\t\t   const void *kernel_function,\n"
  "\t\t\t\t\t   size_t nitems,\n"
  "\t\t\t\t\t   size_t dynamic_shmem_per_block,\n"
  "\t\t\t\t\t   size_t dynamic_shmem_per_thread)\n"
  "{\n"
  "\tcudaError_t\tstatus;\n"
  "\tcl_uint\t\tminGridSize;\n"
  "\tcl_uint\t\tmaxBlockSize;\n"
  "\n"
  "\tstatus = __occupancy_max_potential_block_size(&minGridSize,\n"
  "\t\t\t\t\t\t\t\t\t\t\t\t  &maxBlockSize,\n"
  "\t\t\t\t\t\t\t\t\t\t\t\t  kernel_function,\n"
  "\t\t\t\t\t\t\t\t\t\t\t\t  dynamic_shmem_per_block,\n"
  "\t\t\t\t\t\t\t\t\t\t\t\t  dynamic_shmem_per_thread,\n"
  "\t\t\t\t\t\t\t\t\t\t\t\t  nitems);\n"
  "\tif (status != cudaSuccess)\n"
  "\t\treturn status;\n"
  "\n"
  "\t/* nitems must be less than blockSz.x * gridSz.x */\n"
  "\tif ((size_t)maxBlockSize * (size_t)INT_MAX < nitems)\n"
  "\t\treturn cudaErrorInvalidValue;\n"
  "\n"
  "\tp_block_sz->x = maxBlockSize;\n"
  "\tp_block_sz->y = 1;\n"
  "\tp_block_sz->z = 1;\n"
  "\tp_grid_sz->x = (nitems + (size_t)maxBlockSize - 1) / (size_t)maxBlockSize;\n"
  "\tp_grid_sz->y = 1;\n"
  "\tp_grid_sz->z = 1;\n"
  "\n"
  "\treturn cudaSuccess;\n"
  "}\n"
  "\n"
  "/*\n"
  " * largest_workgroup_size - lead an optimal block_size from the standpoint\n"
  " * of number of threads per block\n"
  " */\n"
  "STATIC_FUNCTION(cudaError_t)\n"
  "largest_workgroup_size(dim3 *p_grid_sz,\n"
  "\t\t\t\t\t   dim3 *p_block_sz,\n"
  "\t\t\t\t\t   const void *kernel_function,\n"
  "\t\t\t\t\t   size_t nitems,\n"
  "\t\t\t\t\t   size_t dynamic_shmem_per_block,\n"
  "\t\t\t\t\t   size_t dynamic_shmem_per_thread)\n"
  "{\n"
  "\tcudaError_t\tstatus;\n"
  "\tcl_int\t\tdevice;\n"
  "\tcl_int\t\twarpSize;\n"
  "\tcl_int\t\tmaxBlockSize;\n"
  "\tcl_int\t\tstaticShmemSize;\n"
  "\tcl_int\t\tmaxShmemSize;\n"
  "\tcl_int\t\tshmemSizeTotal;\n"
  "\tcudaFuncAttributes attrs;\n"
  "\n"
  "\t/* Sanity checks */\n"
  "\tif (!p_grid_sz || !p_block_sz || !kernel_function)\n"
  "\t\treturn cudaErrorInvalidValue;\n"
  "\n"
  "\t/* Get device and function's attribute */\n"
  "\tstatus = cudaGetDevice(&device);\n"
  "\tif (status != cudaSuccess)\n"
  "\t\treturn status;\n"
  "\n"
  "\tstatus = cudaDeviceGetAttribute(&warpSize,\n"
  "\t\t\t\t\t\t\t\t\tcudaDevAttrWarpSize,\n"
  "\t\t\t\t\t\t\t\t\tdevice);\n"
  "\tif (status != cudaSuccess)\n"
  "\t\treturn status;\n"
  "\n"
  "\tstatus = cudaDeviceGetAttribute(&maxShmemSize,\n"
  "\t\t\t\t\t\t\t\t\tcudaDevAttrMaxSharedMemoryPerBlock,\n"
  "\t\t\t\t\t\t\t\t\tdevice);\n"
  "\tif (status != cudaSuccess)\n"
  "\t\treturn status;\n"
  "\n"
  "\tstatus = cudaFuncGetAttributes(&attrs, kernel_function);\n"
  "\tif (status != cudaSuccess)\n"
  "\t\treturn status;\n"
  "\tmaxBlockSize    = attrs.maxThreadsPerBlock;\n"
  "\tstaticShmemSize = attrs.sharedSizeBytes;\n"
  "\n"
  "\t/* only shared memory consumption is what we have to control */\n"
  "\tshmemSizeTotal = (staticShmemSize +\n"
  "\t\t\t\t\t  dynamic_shmem_per_block +\n"
  "\t\t\t\t\t  dynamic_shmem_per_thread * maxBlockSize);\n"
  "\tif (shmemSizeTotal > maxShmemSize)\n"
  "\t{\n"
  "\t\tif (dynamic_shmem_per_thread > 0 &&\n"
  "\t\t\tstaticShmemSize +\n"
  "\t\t\tdynamic_shmem_per_block +\n"
  "\t\t\tdynamic_shmem_per_thread * warpSize <= maxShmemSize)\n"
  "\t\t{\n"
  "\t\t\tmaxBlockSize = (maxShmemSize -\n"
  "\t\t\t\t\t\t\tstaticShmemSize -\n"
  "\t\t\t\t\t\t\tdynamic_shmem_per_block)/dynamic_shmem_per_thread;\n"
  "\t\t\tmaxBlockSize = (maxBlockSize / warpSize) * warpSize;\n"
  "\t\t\tif (maxBlockSize < warpSize)\n"
  "\t\t\t\treturn cudaErrorInvalidValue;\n"
  "\t\t}\n"
  "\t\telse\n"
  "\t\t{\n"
  "\t\t\t/* adjust of block-size makes no sense! */\n"
  "\t\t\treturn cudaErrorInvalidValue;\n"
  "\t\t}\n"
  "\t}\n"
  "\t/* nitems must be less than blockSz.x * gridSz.x */\n"
  "\tif ((size_t)maxBlockSize * (size_t)INT_MAX < nitems)\n"
  "\t\treturn cudaErrorInvalidValue;\n"
  "\n"
  "\tp_block_sz->x = maxBlockSize;\n"
  "\tp_block_sz->y = 1;\n"
  "\tp_block_sz->z = 1;\n"
  "\tp_grid_sz->x = (nitems + maxBlockSize - 1) / maxBlockSize;\n"
  "\tp_grid_sz->y = 1;\n"
  "\tp_grid_sz->z = 1;\n"
  "\n"
  "\treturn cudaSuccess;\n"
  "}\n"
  "\n"
  "/*\n"
  " * kern_arg_t - a uniformed data type to deliver kernel arguments.\n"
  " */\n"
  "typedef devptr_t\t\tkern_arg_t;\n"
  "\n"
  "/*\n"
  " * pgstromLaunchDynamicKernelXX \n"
  " *\n"
  " * A utility routine to launch a kernel function, and then wait for its\n"
  " * completion\n"
  " */\n"
  "STATIC_FUNCTION(cudaError_t)\n"
  "__pgstromLaunchDynamicKernel(void\t\t   *kern_function,\n"
  "\t\t\t\t\t\t\t kern_arg_t\t   *kern_argbuf,\n"
  "\t\t\t\t\t\t\t size_t\t\t\tnum_threads,\n"
  "\t\t\t\t\t\t\t cl_uint\t\tshmem_per_block,\n"
  "\t\t\t\t\t\t\t cl_uint\t\tshmem_per_thread)\n"
  "{\n"
  "\tdim3\t\tgrid_sz;\n"
  "\tdim3\t\tblock_sz;\n"
  "\tcudaError_t\tstatus;\n"
  "\n"
  "\tstatus = optimal_workgroup_size(&grid_sz,\n"
  "\t\t\t\t\t\t\t\t\t&block_sz,\n"
  "\t\t\t\t\t\t\t\t\tkern_function,\n"
  "\t\t\t\t\t\t\t\t\tnum_threads,\n"
  "\t\t\t\t\t\t\t\t\tshmem_per_block,\n"
  "\t\t\t\t\t\t\t\t\tshmem_per_thread);\n"
  "\tif (status != cudaSuccess)\n"
  "\t\treturn status;\n"
  "\n"
  "\tstatus = cudaLaunchDevice(kern_function,\n"
  "\t\t\t\t\t\t\t  kern_argbuf,\n"
  "\t\t\t\t\t\t\t  grid_sz, block_sz,\n"
  "\t\t\t\t\t\t\t  shmem_per_block +\n"
  "\t\t\t\t\t\t\t  shmem_per_thread * block_sz.x,\n"
  "\t\t\t\t\t\t\t  NULL);\n"
  "\tif (status != cudaSuccess)\n"
  "\t\treturn status;\n"
  "\n"
  "\tstatus = cudaDeviceSynchronize();\n"
  "\tif (status != cudaSuccess)\n"
  "\t\treturn status;\n"
  "\n"
  "\treturn cudaSuccess;\n"
  "}\n"
  "\n"
  "STATIC_FUNCTION(cudaError_t)\n"
  "pgstromLaunchDynamicKernel0(void\t   *kern_function,\n"
  "\t\t\t\t\t\t\tsize_t\t\tnum_threads,\n"
  "\t\t\t\t\t\t\tcl_uint\t\tshmem_per_block,\n"
  "\t\t\t\t\t\t\tcl_uint\t\tshmem_per_thread)\n"
  "{\n"
  "\tkern_arg_t  *kern_args = NULL;\n"
  "\n"
  "\treturn __pgstromLaunchDynamicKernel(kern_function,\n"
  "\t\t\t\t\t\t\t\t\t\tkern_args,\n"
  "\t\t\t\t\t\t\t\t\t\tnum_threads,\n"
  "\t\t\t\t\t\t\t\t\t\tshmem_per_block,\n"
  "\t\t\t\t\t\t\t\t\t\tshmem_per_thread);\n"
  "}\n"
  "\n"
  "STATIC_FUNCTION(cudaError_t)\n"
  "pgstromLaunchDynamicKernel1(void\t   *kern_function,\n"
  "\t\t\t\t\t\t\tkern_arg_t\tkarg0,\n"
  "\t\t\t\t\t\t\tsize_t\t\tnum_threads,\n"
  "\t\t\t\t\t\t\tcl_uint\t\tshmem_per_block,\n"
  "\t\t\t\t\t\t\tcl_uint\t\tshmem_per_thread)\n"
  "{\n"
  "\tkern_arg_t  *kern_args = (kern_arg_t *)\n"
  "\t\tcudaGetParameterBuffer(sizeof(kern_arg_t),\n"
  "\t\t\t\t\t\t\t   sizeof(kern_arg_t) * 1);\n"
  "\tif (!kern_args)\n"
  "\t\treturn cudaErrorLaunchOutOfResources;\n"
  "\n"
  "\tkern_args[0] = karg0;\n"
  "\treturn __pgstromLaunchDynamicKernel(kern_function,\n"
  "\t\t\t\t\t\t\t\t\t\tkern_args,\n"
  "\t\t\t\t\t\t\t\t\t\tnum_threads,\n"
  "\t\t\t\t\t\t\t\t\t\tshmem_per_block,\n"
  "\t\t\t\t\t\t\t\t\t\tshmem_per_thread);\n"
  "}\n"
  "\n"
  "STATIC_FUNCTION(cudaError_t)\n"
  "pgstromLaunchDynamicKernel2(void\t   *kern_function,\n"
  "\t\t\t\t\t\t\tkern_arg_t\tkarg0,\n"
  "\t\t\t\t\t\t\tkern_arg_t\tkarg1,\n"
  "\t\t\t\t\t\t\tsize_t\t\tnum_threads,\n"
  "\t\t\t\t\t\t\tcl_uint\t\tshmem_per_block,\n"
  "\t\t\t\t\t\t\tcl_uint\t\tshmem_per_thread)\n"
  "{\n"
  "\tkern_arg_t  *kern_args = (kern_arg_t *)\n"
  "\t\tcudaGetParameterBuffer(sizeof(kern_arg_t),\n"
  "\t\t\t\t\t\t\t   sizeof(kern_arg_t) * 2);\n"
  "\tif (!kern_args)\n"
  "\t\treturn cudaErrorLaunchOutOfResources;\n"
  "\n"
  "\tkern_args[0] = karg0;\n"
  "\tkern_args[1] = karg1;\n"
  "\treturn __pgstromLaunchDynamicKernel(kern_function,\n"
  "\t\t\t\t\t\t\t\t\t\tkern_args,\n"
  "\t\t\t\t\t\t\t\t\t\tnum_threads,\n"
  "\t\t\t\t\t\t\t\t\t\tshmem_per_block,\n"
  "\t\t\t\t\t\t\t\t\t\tshmem_per_thread);\n"
  "}\n"
  "\n"
  "STATIC_FUNCTION(cudaError_t)\n"
  "pgstromLaunchDynamicKernel3(void\t   *kern_function,\n"
  "\t\t\t\t\t\t\tkern_arg_t\tkarg0,\n"
  "\t\t\t\t\t\t\tkern_arg_t\tkarg1,\n"
  "\t\t\t\t\t\t\tkern_arg_t\tkarg2,\n"
  "\t\t\t\t\t\t\tsize_t\t\tnum_threads,\n"
  "\t\t\t\t\t\t\tcl_uint\t\tshmem_per_block,\n"
  "\t\t\t\t\t\t\tcl_uint\t\tshmem_per_thread)\n"
  "{\n"
  "\tkern_arg_t  *kern_args = (kern_arg_t *)\n"
  "\t\tcudaGetParameterBuffer(sizeof(kern_arg_t),\n"
  "\t\t\t\t\t\t\t   sizeof(kern_arg_t) * 3);\n"
  "\tif (!kern_args)\n"
  "\t\treturn cudaErrorLaunchOutOfResources;\n"
  "\n"
  "\tkern_args[0] = karg0;\n"
  "\tkern_args[1] = karg1;\n"
  "\tkern_args[2] = karg2;\n"
  "\treturn __pgstromLaunchDynamicKernel(kern_function,\n"
  "\t\t\t\t\t\t\t\t\t\tkern_args,\n"
  "\t\t\t\t\t\t\t\t\t\tnum_threads,\n"
  "\t\t\t\t\t\t\t\t\t\tshmem_per_block,\n"
  "\t\t\t\t\t\t\t\t\t\tshmem_per_thread);\n"
  "}\n"
  "\n"
  "STATIC_FUNCTION(cudaError_t)\n"
  "pgstromLaunchDynamicKernel4(void\t   *kern_function,\n"
  "\t\t\t\t\t\t\tkern_arg_t\tkarg0,\n"
  "\t\t\t\t\t\t\tkern_arg_t\tkarg1,\n"
  "\t\t\t\t\t\t\tkern_arg_t\tkarg2,\n"
  "\t\t\t\t\t\t\tkern_arg_t\tkarg3,\n"
  "\t\t\t\t\t\t\tsize_t\t\tnum_threads,\n"
  "\t\t\t\t\t\t\tcl_uint\t\tshmem_per_block,\n"
  "\t\t\t\t\t\t\tcl_uint\t\tshmem_per_thread)\n"
  "{\n"
  "\tkern_arg_t  *kern_args = (kern_arg_t *)\n"
  "\t\tcudaGetParameterBuffer(sizeof(kern_arg_t),\n"
  "\t\t\t\t\t\t\t   sizeof(kern_arg_t) * 4);\n"
  "\tif (!kern_args)\n"
  "\t\treturn cudaErrorLaunchOutOfResources;\n"
  "\n"
  "\tkern_args[0] = karg0;\n"
  "\tkern_args[1] = karg1;\n"
  "\tkern_args[2] = karg2;\n"
  "\tkern_args[3] = karg3;\n"
  "\treturn __pgstromLaunchDynamicKernel(kern_function,\n"
  "\t\t\t\t\t\t\t\t\t\tkern_args,\n"
  "\t\t\t\t\t\t\t\t\t\tnum_threads,\n"
  "\t\t\t\t\t\t\t\t\t\tshmem_per_block,\n"
  "\t\t\t\t\t\t\t\t\t\tshmem_per_thread);\n"
  "}\n"
  "\n"
  "STATIC_FUNCTION(cudaError_t)\n"
  "pgstromLaunchDynamicKernel5(void\t   *kern_function,\n"
  "\t\t\t\t\t\t\tkern_arg_t\tkarg0,\n"
  "\t\t\t\t\t\t\tkern_arg_t\tkarg1,\n"
  "\t\t\t\t\t\t\tkern_arg_t\tkarg2,\n"
  "\t\t\t\t\t\t\tkern_arg_t\tkarg3,\n"
  "\t\t\t\t\t\t\tkern_arg_t\tkarg4,\n"
  "\t\t\t\t\t\t\tsize_t\t\tnum_threads,\n"
  "\t\t\t\t\t\t\tcl_uint\t\tshmem_per_block,\n"
  "\t\t\t\t\t\t\tcl_uint\t\tshmem_per_thread)\n"
  "{\n"
  "\tkern_arg_t  *kern_args = (kern_arg_t *)\n"
  "\t\tcudaGetParameterBuffer(sizeof(kern_arg_t),\n"
  "\t\t\t\t\t\t\t   sizeof(kern_arg_t) * 5);\n"
  "\tif (!kern_args)\n"
  "\t\treturn cudaErrorLaunchOutOfResources;\n"
  "\n"
  "\tkern_args[0] = karg0;\n"
  "\tkern_args[1] = karg1;\n"
  "\tkern_args[2] = karg2;\n"
  "\tkern_args[3] = karg3;\n"
  "\tkern_args[4] = karg4;\n"
  "\treturn __pgstromLaunchDynamicKernel(kern_function,\n"
  "\t\t\t\t\t\t\t\t\t\tkern_args,\n"
  "\t\t\t\t\t\t\t\t\t\tnum_threads,\n"
  "\t\t\t\t\t\t\t\t\t\tshmem_per_block,\n"
  "\t\t\t\t\t\t\t\t\t\tshmem_per_thread);\n"
  "}\n"
  "\n"
  "STATIC_FUNCTION(cudaError_t)\n"
  "pgstromLaunchDynamicKernel6(void\t   *kern_function,\n"
  "\t\t\t\t\t\t\tkern_arg_t\tkarg0,\n"
  "\t\t\t\t\t\t\tkern_arg_t\tkarg1,\n"
  "\t\t\t\t\t\t\tkern_arg_t\tkarg2,\n"
  "\t\t\t\t\t\t\tkern_arg_t\tkarg3,\n"
  "\t\t\t\t\t\t\tkern_arg_t\tkarg4,\n"
  "\t\t\t\t\t\t\tkern_arg_t\tkarg5,\n"
  "\t\t\t\t\t\t\tsize_t\t\tnum_threads,\n"
  "\t\t\t\t\t\t\tcl_uint\t\tshmem_per_block,\n"
  "\t\t\t\t\t\t\tcl_uint\t\tshmem_per_thread)\n"
  "{\n"
  "\tkern_arg_t  *kern_args = (kern_arg_t *)\n"
  "\t\tcudaGetParameterBuffer(sizeof(kern_arg_t),\n"
  "\t\t\t\t\t\t\t   sizeof(kern_arg_t) * 6);\n"
  "\tif (!kern_args)\n"
  "\t\treturn cudaErrorLaunchOutOfResources;\n"
  "\n"
  "\tkern_args[0] = karg0;\n"
  "\tkern_args[1] = karg1;\n"
  "\tkern_args[2] = karg2;\n"
  "\tkern_args[3] = karg3;\n"
  "\tkern_args[4] = karg4;\n"
  "\tkern_args[5] = karg5;\n"
  "\treturn __pgstromLaunchDynamicKernel(kern_function,\n"
  "\t\t\t\t\t\t\t\t\t\tkern_args,\n"
  "\t\t\t\t\t\t\t\t\t\tnum_threads,\n"
  "\t\t\t\t\t\t\t\t\t\tshmem_per_block,\n"
  "\t\t\t\t\t\t\t\t\t\tshmem_per_thread);\n"
  "}\n"
  "\n"
  "STATIC_FUNCTION(cudaError_t)\n"
  "pgstromLaunchDynamicKernel7(void\t   *kern_function,\n"
  "\t\t\t\t\t\t\tkern_arg_t\tkarg0,\n"
  "\t\t\t\t\t\t\tkern_arg_t\tkarg1,\n"
  "\t\t\t\t\t\t\tkern_arg_t\tkarg2,\n"
  "\t\t\t\t\t\t\tkern_arg_t\tkarg3,\n"
  "\t\t\t\t\t\t\tkern_arg_t\tkarg4,\n"
  "\t\t\t\t\t\t\tkern_arg_t\tkarg5,\n"
  "\t\t\t\t\t\t\tkern_arg_t\tkarg6,\n"
  "\t\t\t\t\t\t\tsize_t\t\tnum_threads,\n"
  "\t\t\t\t\t\t\tcl_uint\t\tshmem_per_block,\n"
  "\t\t\t\t\t\t\tcl_uint\t\tshmem_per_thread)\n"
  "{\n"
  "\tkern_arg_t  *kern_args = (kern_arg_t *)\n"
  "\t\tcudaGetParameterBuffer(sizeof(kern_arg_t),\n"
  "\t\t\t\t\t\t\t   sizeof(kern_arg_t) * 7);\n"
  "\tif (!kern_args)\n"
  "\t\treturn cudaErrorLaunchOutOfResources;\n"
  "\n"
  "\tkern_args[0] = karg0;\n"
  "\tkern_args[1] = karg1;\n"
  "\tkern_args[2] = karg2;\n"
  "\tkern_args[3] = karg3;\n"
  "\tkern_args[4] = karg4;\n"
  "\tkern_args[5] = karg5;\n"
  "\tkern_args[6] = karg6;\n"
  "\treturn __pgstromLaunchDynamicKernel(kern_function,\n"
  "\t\t\t\t\t\t\t\t\t\tkern_args,\n"
  "\t\t\t\t\t\t\t\t\t\tnum_threads,\n"
  "\t\t\t\t\t\t\t\t\t\tshmem_per_block,\n"
  "\t\t\t\t\t\t\t\t\t\tshmem_per_thread);\n"
  "}\n"
  "\n"
  "STATIC_FUNCTION(cudaError_t)\n"
  "pgstromLaunchDynamicKernel8(void\t   *kern_function,\n"
  "\t\t\t\t\t\t\tkern_arg_t\tkarg0,\n"
  "\t\t\t\t\t\t\tkern_arg_t\tkarg1,\n"
  "\t\t\t\t\t\t\tkern_arg_t\tkarg2,\n"
  "\t\t\t\t\t\t\tkern_arg_t\tkarg3,\n"
  "\t\t\t\t\t\t\tkern_arg_t\tkarg4,\n"
  "\t\t\t\t\t\t\tkern_arg_t\tkarg5,\n"
  "\t\t\t\t\t\t\tkern_arg_t\tkarg6,\n"
  "\t\t\t\t\t\t\tkern_arg_t\tkarg7,\n"
  "\t\t\t\t\t\t\tsize_t\t\tnum_threads,\n"
  "\t\t\t\t\t\t\tcl_uint\t\tshmem_per_block,\n"
  "\t\t\t\t\t\t\tcl_uint\t\tshmem_per_thread)\n"
  "{\n"
  "\tkern_arg_t  *kern_args = (kern_arg_t *)\n"
  "\t\tcudaGetParameterBuffer(sizeof(kern_arg_t),\n"
  "\t\t\t\t\t\t\t   sizeof(kern_arg_t) * 8);\n"
  "\tif (!kern_args)\n"
  "\t\treturn cudaErrorLaunchOutOfResources;\n"
  "\n"
  "\tkern_args[0] = karg0;\n"
  "\tkern_args[1] = karg1;\n"
  "\tkern_args[2] = karg2;\n"
  "\tkern_args[3] = karg3;\n"
  "\tkern_args[4] = karg4;\n"
  "\tkern_args[5] = karg5;\n"
  "\tkern_args[6] = karg6;\n"
  "\tkern_args[7] = karg7;\n"
  "\treturn __pgstromLaunchDynamicKernel(kern_function,\n"
  "\t\t\t\t\t\t\t\t\t\tkern_args,\n"
  "\t\t\t\t\t\t\t\t\t\tnum_threads,\n"
  "\t\t\t\t\t\t\t\t\t\tshmem_per_block,\n"
  "\t\t\t\t\t\t\t\t\t\tshmem_per_thread);\n"
  "}\n"
  "\n"
  "STATIC_FUNCTION(cudaError_t)\n"
  "pgstromLaunchDynamicKernel9(void\t   *kern_function,\n"
  "\t\t\t\t\t\t\tkern_arg_t\tkarg0,\n"
  "\t\t\t\t\t\t\tkern_arg_t\tkarg1,\n"
  "\t\t\t\t\t\t\tkern_arg_t\tkarg2,\n"
  "\t\t\t\t\t\t\tkern_arg_t\tkarg3,\n"
  "\t\t\t\t\t\t\tkern_arg_t\tkarg4,\n"
  "\t\t\t\t\t\t\tkern_arg_t\tkarg5,\n"
  "\t\t\t\t\t\t\tkern_arg_t\tkarg6,\n"
  "\t\t\t\t\t\t\tkern_arg_t\tkarg7,\n"
  "\t\t\t\t\t\t\tkern_arg_t\tkarg8,\n"
  "\t\t\t\t\t\t\tsize_t\t\tnum_threads,\n"
  "\t\t\t\t\t\t\tcl_uint\t\tshmem_per_block,\n"
  "\t\t\t\t\t\t\tcl_uint\t\tshmem_per_thread)\n"
  "{\n"
  "\tkern_arg_t  *kern_args = (kern_arg_t *)\n"
  "\t\tcudaGetParameterBuffer(sizeof(kern_arg_t),\n"
  "\t\t\t\t\t\t\t   sizeof(kern_arg_t) * 9);\n"
  "\tif (!kern_args)\n"
  "\t\treturn cudaErrorLaunchOutOfResources;\n"
  "\n"
  "\tkern_args[0] = karg0;\n"
  "\tkern_args[1] = karg1;\n"
  "\tkern_args[2] = karg2;\n"
  "\tkern_args[3] = karg3;\n"
  "\tkern_args[4] = karg4;\n"
  "\tkern_args[5] = karg5;\n"
  "\tkern_args[6] = karg6;\n"
  "\tkern_args[7] = karg7;\n"
  "\tkern_args[8] = karg8;\n"
  "\treturn __pgstromLaunchDynamicKernel(kern_function,\n"
  "\t\t\t\t\t\t\t\t\t\tkern_args,\n"
  "\t\t\t\t\t\t\t\t\t\tnum_threads,\n"
  "\t\t\t\t\t\t\t\t\t\tshmem_per_block,\n"
  "\t\t\t\t\t\t\t\t\t\tshmem_per_thread);\n"
  "}\n"
  "\n"
  "#endif\t/* __CUDACC__ */\n"
  "#undef WORKGROUPSIZE_RESULT_TYPE\n"
  "#undef WORKGROUPSIZE_RESULT_SUCCESS\n"
  "#undef WORKGROUPSIZE_RESULT_EINVAL\n"
  "#endif\t/* CUDA_DYNPARA_H */\n"
;
